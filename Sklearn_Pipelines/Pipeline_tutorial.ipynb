{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas, Pipelines, and Custom Transformers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An educational video on simplifying complex preprocessing from Julie Michelman's presentation for the 2017 PyData conference. I followed this in order to get a stronger grasp of the Scikit-Learn Pipelines.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Special_Events_Permits_2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_date</th>\n",
       "      <th>permit_status</th>\n",
       "      <th>permit_type</th>\n",
       "      <th>event_category</th>\n",
       "      <th>event_sub_category</th>\n",
       "      <th>name_of_event</th>\n",
       "      <th>year_month_app</th>\n",
       "      <th>event_start_date</th>\n",
       "      <th>event_end_date</th>\n",
       "      <th>event_location_park</th>\n",
       "      <th>event_location_neighborhood</th>\n",
       "      <th>council_district</th>\n",
       "      <th>precinct</th>\n",
       "      <th>organization</th>\n",
       "      <th>attendance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/09/2015 12:00:00 AM</td>\n",
       "      <td>Complete</td>\n",
       "      <td>Special Event</td>\n",
       "      <td>Athletic</td>\n",
       "      <td>Run/Walk</td>\n",
       "      <td>See Jane Run Women's Half Marathon and 5K</td>\n",
       "      <td>S16JY044</td>\n",
       "      <td>07/10/2016 12:00:00 AM</td>\n",
       "      <td>07/10/2016 12:00:00 AM</td>\n",
       "      <td>Gas Works Park</td>\n",
       "      <td>Multiple Neighborhoods</td>\n",
       "      <td>3</td>\n",
       "      <td>North</td>\n",
       "      <td>See Jane Run</td>\n",
       "      <td>4500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/07/2016 12:00:00 AM</td>\n",
       "      <td>Complete</td>\n",
       "      <td>Special Event</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Capitol Hill Block Party</td>\n",
       "      <td>S16JY046</td>\n",
       "      <td>07/22/2016 12:00:00 AM</td>\n",
       "      <td>07/24/2016 12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Capitol Hill</td>\n",
       "      <td>3</td>\n",
       "      <td>East</td>\n",
       "      <td>Independent Event Solutions</td>\n",
       "      <td>27000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/21/2016 12:00:00 AM</td>\n",
       "      <td>Complete</td>\n",
       "      <td>Special Event</td>\n",
       "      <td>Community</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sounders FC March to the Match (7.09)</td>\n",
       "      <td>S16JY074</td>\n",
       "      <td>07/09/2016 12:00:00 AM</td>\n",
       "      <td>07/09/2016 12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pioneer Square</td>\n",
       "      <td>3</td>\n",
       "      <td>West</td>\n",
       "      <td>Seattle Sounders FC</td>\n",
       "      <td>705.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/21/2016 12:00:00 AM</td>\n",
       "      <td>Complete</td>\n",
       "      <td>Special Event</td>\n",
       "      <td>Community</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sounders FC March to the Match (7.13)</td>\n",
       "      <td>S16JY075</td>\n",
       "      <td>07/13/2016 12:00:00 AM</td>\n",
       "      <td>07/13/2016 12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pioneer Square</td>\n",
       "      <td>3</td>\n",
       "      <td>West</td>\n",
       "      <td>Seattle Sounders FC</td>\n",
       "      <td>705.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/21/2016 12:00:00 AM</td>\n",
       "      <td>Complete</td>\n",
       "      <td>Special Event</td>\n",
       "      <td>Community</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sounders FC March to the Match (7.31)</td>\n",
       "      <td>S16JY076</td>\n",
       "      <td>07/31/2016 12:00:00 AM</td>\n",
       "      <td>07/31/2016 12:00:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pioneer Square</td>\n",
       "      <td>3</td>\n",
       "      <td>West</td>\n",
       "      <td>Seattle Sounders FC</td>\n",
       "      <td>705.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         application_date permit_status    permit_type event_category  \\\n",
       "0  12/09/2015 12:00:00 AM      Complete  Special Event       Athletic   \n",
       "1  01/07/2016 12:00:00 AM      Complete  Special Event     Commercial   \n",
       "2  01/21/2016 12:00:00 AM      Complete  Special Event      Community   \n",
       "3  01/21/2016 12:00:00 AM      Complete  Special Event      Community   \n",
       "4  01/21/2016 12:00:00 AM      Complete  Special Event      Community   \n",
       "\n",
       "  event_sub_category                              name_of_event  \\\n",
       "0           Run/Walk  See Jane Run Women's Half Marathon and 5K   \n",
       "1                NaN                   Capitol Hill Block Party   \n",
       "2                NaN      Sounders FC March to the Match (7.09)   \n",
       "3                NaN      Sounders FC March to the Match (7.13)   \n",
       "4                NaN      Sounders FC March to the Match (7.31)   \n",
       "\n",
       "  year_month_app        event_start_date          event_end_date  \\\n",
       "0       S16JY044  07/10/2016 12:00:00 AM  07/10/2016 12:00:00 AM   \n",
       "1       S16JY046  07/22/2016 12:00:00 AM  07/24/2016 12:00:00 AM   \n",
       "2       S16JY074  07/09/2016 12:00:00 AM  07/09/2016 12:00:00 AM   \n",
       "3       S16JY075  07/13/2016 12:00:00 AM  07/13/2016 12:00:00 AM   \n",
       "4       S16JY076  07/31/2016 12:00:00 AM  07/31/2016 12:00:00 AM   \n",
       "\n",
       "  event_location_park event_location_neighborhood council_district precinct  \\\n",
       "0      Gas Works Park      Multiple Neighborhoods                3    North   \n",
       "1                 NaN                Capitol Hill                3     East   \n",
       "2                 NaN              Pioneer Square                3     West   \n",
       "3                 NaN              Pioneer Square                3     West   \n",
       "4                 NaN              Pioneer Square                3     West   \n",
       "\n",
       "                  organization  attendance  \n",
       "0                 See Jane Run      4500.0  \n",
       "1  Independent Event Solutions     27000.0  \n",
       "2          Seattle Sounders FC       705.0  \n",
       "3          Seattle Sounders FC       705.0  \n",
       "4          Seattle Sounders FC       705.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are we going to do?\n",
    "- outcome -> permit_status (binary)\n",
    "- features -> everything else! (raw, transformed, combinations, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set aside test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define outcome, we will use one feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# define the outcome using the Numpy.where function\n",
    "y_train = np.where(df_train.permit_status == 'Complete', 1, 0)\n",
    "y_test = np.where(df_test.permit_status == 'Complete', 1, 0)\n",
    "# We're going to keep it simple and just use attendance as a feature for our model\n",
    "# In case of any null-values, will fill those in with 0's\n",
    "X_train = df_train[['attendance']].fillna(value=0)\n",
    "X_test = df_test[['attendance']].fillna(value=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model and predict on training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit the model on the training data and we can form predictions from that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model to the data so it knows what to predict and what to use in order to do so\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# this will produce a class prediction (0 or 1)\n",
    "y_pred_train = model.predict(X_train)\n",
    "\n",
    "# this will produce a probability prediction\n",
    "p_pred_train = model.predict_proba(X_train)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also predict on the test data, this will help us evaluate how well the model performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's good to start with a baseline: if we come up with the dumbest model we can think of to start off with.\n",
    "In this case, we take the average of the labels of the training set and repeat that for the length of the training set. Next, we use the predict_proba function to get the outcomes for the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have basically two things:\n",
    "- predicted values (which are all the mean of the y of the training set)\n",
    "- the predicted probabilities of the y_test using a predictive model that takes X_test as an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dumb model that uses only the means\n",
    "p_baseline_test = [y_train.mean()]*len(y_test)\n",
    "\n",
    "# smarter model to predict probabilities\n",
    "p_pred_test = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure performance on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use auc scores to evaluate the performance of both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.4504065040650407\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# evaluate baseline model by comparing the y_test values and the baseline_test outcomes\n",
    "auc_baseline = roc_auc_score(y_test, p_baseline_test)\n",
    "print(auc_baseline) \n",
    "# evaluate the smarter model by comparing the y_test with the p_pred_test outcomes\n",
    "auc_test = roc_auc_score(y_test, p_pred_test)\n",
    "print(auc_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers & Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***transformer*** (for data preparation)\n",
    "\n",
    "Transformers are for data preparation. Transformers transform input data (x) in some ways.\n",
    "- has a fit() method: what this does is it takes the training data and finds all the parameters that the transformer estimator needs.\n",
    "- has a **transform(X, y)** method: applies the transformation to the training data or test data.\n",
    "\n",
    "***Estimator*** (for modeling)\n",
    "\n",
    "Estimator predicts a new value (or values) (y) by using the input data (X). \n",
    "- Also has a fit() method because it needs to learn the data\n",
    "- The estimator has the **predict(X)** method which should output the predicted y value from the given X.\n",
    "\n",
    "fit() does not return any value, it simply stores the learnt data inside the object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ****For example****\n",
    "\n",
    "You use the **StandardScaler** transformer in order to standardize features. \n",
    "- fit(): find mean, standard deviation of each feature.\n",
    "- transform(): subtract mean, divide by standard deviation\n",
    "\n",
    "Then, you use the **LogisticRegression** estimator for predictions. \n",
    "- fit(): find coefficients in logistic regression formula.\n",
    "- predict(): plug into formula, get predicted class from predicted probability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you want to go through multiple transformations in the course of feature engeneering. Code can get a bit messy if we work with multiple transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, Scikit-Learn has ***Pipelines***, which work as meta-transformers which take your whole list of transformers and apply them in a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import (PolynomialFeatures, StandardScaler)\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "Imputer = SimpleImputer\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', Imputer()),\n",
    "    ('quadratic', PolynomialFeatures()),\n",
    "    ('standardizer', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could easily write something like this to get the pipeline going:\n",
    "\n",
    "- X_train = pipeline.fit_transform(X_train_raw)\n",
    "- X_test = pipeline.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers in Parrallel\n",
    "\n",
    "Sometimes you want to try out more than one transformation. For example, should we impute with a mean or median or most_frequent value? Which one works best?\n",
    "\n",
    "Let our machine learning algorithm decide for us!\n",
    "\n",
    "FeatureUnion concatenates results of multiple transformer objects. This estimator applies a list of transformer objects in parallel to the input data, then concatenates the results. This is useful to combine several feature extraction mechanisms into a single transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "feature_union = FeatureUnion ([\n",
    "    ('fill_avg', Imputer(strategy='mean')),\n",
    "    ('fill_mid', Imputer(strategy='median')),\n",
    "    ('fill_freq', Imputer(strategy='most_frequent'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could write this easily:\n",
    "- X_train = feature_union.fit_transform(X_train_raw)\n",
    "- X_test = feature_union.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's take a look at the event_location_park column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                366\n",
       "Gas Works Park       7\n",
       "Magnuson Park        5\n",
       "Lake Union Park      2\n",
       "Occidental Park      2\n",
       "Name: event_location_park, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.event_location_park.value_counts(dropna=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over 350 of them are NaNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimated attendance: a few missing, right-skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another interesting column is the attendance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "attendance    251000.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out whether there are any missing values easily.\n",
    "X_train.attendance.isnull().sum()\n",
    "# check out if there is any infinity present.\n",
    "X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a2d7146d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEICAYAAAC0+DhzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAbfklEQVR4nO3de5gddZ3n8feHBMJVrg0TcyGAQQQXQ2xCXByHAUSIo4EZ0LAjRESjA+zKelkCukMcN/vAPHKRhx0gLIyBUSCiDBmE0chFlt2RECSEBIg0EEmbmAQhJBkkGPjuH/U7UOk6ffp0SJ066f68nqeeU/WrX1V9f6dOn2/Xry5HEYGZmVnedlUHYGZm7cfJwczMCpwczMyswMnBzMwKnBzMzKzAycHMzAqcHGyrk7RE0jFVx1ElSadIWi5pg6Qjqo6nGZJC0nuqjsPag5OD9YukZZKO71H2WUkP1aYj4rCIeKCP9YxJX0ZDSwq1at8BzouIXSPisXoVlHlO0pN15j0g6fM9yvzlbS3j5GADUhsknf2BJX3U+QiwL3CgpCPLD8mseU4OttXljy4kTZC0QNI6SaskXZ6qPZhe16aulw9J2k7SNyX9RtJqSTdJ2j233jPTvN9L+u89tjND0u2S/knSOuCzadv/JmmtpJWSrpa0Q259IekcSc9IWi/p25IOSsuskzQnX79HG+vGKmmYpA3AEOBxSc82eKumAncCd6fx2rpnAn8KXJ3em6sl1d6vx1PZp1Pdv5C0MLXx/0k6vMd++JqkRZJekXSbpB1z87+e3pcVkj7Xo30fl/RYeh+WS5qRm1c76psq6QVJL0r6Rm7+EEkXSXo2va+PShqV5h0iaZ6klyQtlfSpBu+PVSkiPHhoegCWAcf3KPss8FC9OsC/AWek8V2BiWl8DBDA0NxynwO6gANT3R8DN6d5hwIbgA8DO5B12/wxt50Zafpksn96dgI+CEwEhqbtPQWcn9teAHOBdwGHARuBe9P2dweeBKb28j70Gmtu3e9p8D7uDKwDJgF/BbwI7JCb/wDw+R7LbLZOYDywGjiKLBlNTe/9sNx+mA+8G9grtf9Lad6JwCrg/cAuwA/y6weOAf5Dei8PT3VP7rHvrk/v8wfSe/e+NP/rwBPAewGl+Xun7SwHzkr7ZHxq92FVf6491PmMVh2Ah21rSF84G4C1ueFVek8ODwLfAvbpsZ7aF0w+OdwLnJObfi/ZF/5Q4G+BW3LzdgZeZ/Pk8GAfsZ8P3JGbDuDo3PSjwAW56cuAK3tZV6+x5tbdKDl8BliT2jYsvY+n5OY/QN/J4Rrg2z3qLAX+LLcfPpOb9/fAtWn8RuCS3LyDG8UMXAlc0WPfjczNnw9MycUwuc46Pg38nx5l1wEXV/259lAc3K1kW+LkiNijNgDnNKh7NtkXz9OSHpH0Fw3qvhv4TW76N2RfnvulectrMyLiVeD3PZZfnp+QdLCkuyT9LnU1/U9gnx7LrMqN/6HO9K5bEGszpgJzImJTRGwkO/KY2scyPe0PfDV1Ka2VtBYYlWKr+V1u/FXebs9m7yebtwVJR0m6X9IaSa8AX6L43vW27lFAve60/YGjesT718Cf9NVQa72qT9rZABcRzwCnS9oO+Evgdkl7k/3n2dMKsi+QmtHAJrIv7JVk/50DIGknsq6KzTbXY/oa4DHg9IhYL+l84NR30JxmY21I0kjgWGCCpL9KxTsDO0raJyJepP7709NyYGZEzOxX5JmVZF/iNaN7zP8BcDVwUkS8JulKismhUVwHAYvrlP8iIj66BfFai/nIwUol6TOSOiLiTbKuE4A3yLpU3iTrs6+5Bfivkg6QtCvZf/q3RcQm4HbgE5L+YzpJ/C2y/uxGdiPr198g6RDgb7ZawxrH2pczgF+TJbtxaTgY6AZOT3VWsfl7U6/seuBL6b98SdolnUjerYkY5pCdtD9U0s7AxT3m7wa8lBLDBOA/NbHOmv8NfFvS2BTX4ekfgruAgyWdIWn7NBwp6X39WLe1iJODle1EYEm6gue7ZP3Sr6VuoZnA/01dDBPJ+sFvJjtP8TzwGvCfASJiSRq/ley/3vVkJ2M3Ntj218i+1NaTfZHethXb1WusTZgK/ENE/C4/ANfydtfSd4FTJb0s6apUNgOYnd6vT0XEAuALZP/hv0x2gvyzzQQQEfeQnUe4Ly13X48q5wB/J2k92fmeOU22DeDyVP9nZMn5BmCniFgPnABMITvy+h1wKdk5F2szivCP/di2J/23vhYYGxHPVx2P2UDjIwfbZkj6hKSdJe1CdinrE2RX5JjZVlZ6ckg3xDwm6a40fYCkh5XdeHRb6j8m3Tx0m6SuNH9M2bHZNmcyWXfECmAsWReVD33NStCKI4cvk918U3Mp2fXSY8n6Sc9O5WcDL0fEe4ArUj2zt0TE59Pls7tHxHERsbTqmMwGqlKTQ7pk7+NkVy8gSWSX8N2eqswmu6MVsv8KZ6fx24HjUn0zM2uxsu9zuBL4b2SXxUF2Xfra3OV+3cCIND6CdFNORGxKN97sTXZ7/VskTQOmAeyyyy4fPOSQQ0ptgJnZQPPoo4++GBEdjeqUlhzSnbCrI+JRvf1s/3pHAtHEvLcLImYBswA6OztjwYIFWyFaM7PBQ9Jv+qpT5pHD0cAnJU0CdiR7uNmVwB6Shqajh5FkJxchO4oYBXQre9zy7sBLJcZnZma9KO2cQ0RcGBEjI2IM2U0v90XEXwP38/YjDGqPLIbs6Zi1G4BOTfV9JYqZWQWquM/hAuArkrrIzinckMpvAPZO5V8BplcQm5mZ0aIH70X2k5EPpPHngAl16rwGnNaKeMzMrDHfIW1mZgVODmZmVuDkYGZmBU4OZmZW4ORgZmYFg/ZnQsdM/0ll2152yccr27aZWTN85GBmZgVODmZmVuDkYGZmBU4OZmZW4ORgZmYFTg5mZlbg5GBmZgVODmZmVuDkYGZmBU4OZmZW4ORgZmYFTg5mZlZQWnKQtKOk+ZIel7RE0rdS+fckPS9pYRrGpXJJukpSl6RFksaXFZuZmTVW5lNZNwLHRsQGSdsDD0m6J837ekTc3qP+ScDYNBwFXJNezcysxUo7cojMhjS5fRqiwSKTgZvScr8E9pA0vKz4zMysd6Wec5A0RNJCYDUwLyIeTrNmpq6jKyQNS2UjgOW5xbtTmZmZtVipySEi3oiIccBIYIKk9wMXAocARwJ7ARek6qq3ip4FkqZJWiBpwZo1a0qK3MxscGvJ1UoRsRZ4ADgxIlamrqONwD8CE1K1bmBUbrGRwIo665oVEZ0R0dnR0VFy5GZmg1OZVyt1SNojje8EHA88XTuPIEnAycDitMhc4Mx01dJE4JWIWFlWfGZm1rsyr1YaDsyWNIQsCc2JiLsk3Sepg6wbaSHwpVT/bmAS0AW8CpxVYmxmZtZAackhIhYBR9QpP7aX+gGcW1Y8ZmbWPN8hbWZmBU4OZmZW4ORgZmYFTg5mZlbg5GBmZgVODmZmVuDkYGZmBU4OZmZW4ORgZmYFTg5mZlbg5GBmZgVODmZmVuDkYGZmBU4OZmZW4ORgZmYFTg5mZlbg5GBmZgVODmZmVuDkYGZmBaUlB0k7Spov6XFJSyR9K5UfIOlhSc9Iuk3SDql8WJruSvPHlBWbmZk1VuaRw0bg2Ij4ADAOOFHSROBS4IqIGAu8DJyd6p8NvBwR7wGuSPXMzKwCpSWHyGxIk9unIYBjgdtT+Wzg5DQ+OU2T5h8nSWXFZ2ZmvSv1nIOkIZIWAquBecCzwNqI2JSqdAMj0vgIYDlAmv8KsHeddU6TtEDSgjVr1pQZvpnZoFVqcoiINyJiHDASmAC8r1619FrvKCEKBRGzIqIzIjo7Ojq2XrBmZvaWllytFBFrgQeAicAekoamWSOBFWm8GxgFkObvDrzUivjMzGxzZV6t1CFpjzS+E3A88BRwP3BqqjYVuDONz03TpPn3RUThyMHMzMo3tO8qW2w4MFvSELIkNCci7pL0JHCrpP8BPAbckOrfANwsqYvsiGFKibGZmVkDpSWHiFgEHFGn/Dmy8w89y18DTisrHjMza57vkDYzswInBzMzK3ByMDOzAicHMzMrcHIwM7MCJwczMytwcjAzswInBzMzK3ByMDOzAicHMzMrcHIwM7MCJwczMytwcjAzswInBzMzK3ByMDOzAicHMzMrcHIwM7MCJwczMysoLTlIGiXpfklPSVoi6cupfIak30pamIZJuWUulNQlaamkj5UVm5mZNVbab0gDm4CvRsSvJO0GPCppXpp3RUR8J19Z0qHAFOAw4N3AzyUdHBFvlBijmZnVUdqRQ0SsjIhfpfH1wFPAiAaLTAZujYiNEfE80AVMKCs+MzPrXUvOOUgaAxwBPJyKzpO0SNKNkvZMZSOA5bnFuqmTTCRNk7RA0oI1a9aUGLWZ2eBVenKQtCvwI+D8iFgHXAMcBIwDVgKX1arWWTwKBRGzIqIzIjo7OjpKitrMbHArNTlI2p4sMXw/In4MEBGrIuKNiHgTuJ63u466gVG5xUcCK8qMz8zM6msqOUh6f39XLEnADcBTEXF5rnx4rtopwOI0PheYImmYpAOAscD8/m7XzMzeuWavVrpW0g7A94AfRMTaJpY5GjgDeELSwlR2EXC6pHFkXUbLgC8CRMQSSXOAJ8mudDrXVyqZmVWjqeQQER+WNBb4HLBA0nzgHyNiXoNlHqL+eYS7GywzE5jZTExmZlaeps85RMQzwDeBC4A/A66S9LSkvywrODMzq0az5xwOl3QF2b0KxwKfiIj3pfErSozPzMwq0Ow5h6vJriy6KCL+UCuMiBWSvllKZGZmVplmk8Mk4A+1E8SStgN2jIhXI+Lm0qIzM7NKNHvO4efATrnpnVOZmZkNQM0mhx0jYkNtIo3vXE5IZmZWtWaTw79LGl+bkPRB4A8N6puZ2Tas2XMO5wM/lFR7nMVw4NPlhGRmZlVr9ia4RyQdAryX7Ma2pyPij6VGZmZmlenPj/0cCYxJyxwhiYi4qZSozMysUk0lB0k3kz1meyFQe95RAE4OZmYDULNHDp3AoRFR+H0FMzMbeJq9Wmkx8CdlBmJmZu2j2SOHfYAn09NYN9YKI+KTpURlZmaVajY5zCgzCDMzay/NXsr6C0n7A2Mj4ueSdgaGlBuamZlVpdlHdn8BuB24LhWNAP65rKDMzKxazZ6QPpfsZz/XwVs//LNvWUGZmVm1mk0OGyPi9dqEpKFk9zn0StIoSfdLekrSEklfTuV7SZon6Zn0umcql6SrJHVJWpR/lpOZmbVWs8nhF5IuAnaS9FHgh8C/9LHMJuCr6RfjJgLnSjoUmA7cGxFjgXvTNMBJwNg0TAOu6VdLzMxsq2k2OUwH1gBPAF8E7ib7PeleRcTKiPhVGl9P9hOjI4DJwOxUbTZwchqfDNwUmV8Ce0ga3o+2mJnZVtLs1Upvkv1M6PVbshFJY4AjgIeB/SJiZVrvSkm1cxcjgOW5xbpT2coe65pGdmTB6NGjtyQcMzPrQ7PPVnqeOucYIuLAJpbdFfgRcH5ErJPUa9U6ZfW2OQuYBdDZ2enHeZiZlaA/z1aq2RE4Ddirr4UkbU+WGL4fET9OxaskDU9HDcOB1am8GxiVW3wksAIzM2u5ps45RMTvc8NvI+JK4NhGyyg7RLgBeCoiLs/NmgtMTeNTgTtz5Wemq5YmAq/Uup/MzKy1mu1Wyl9Wuh3ZkcRufSx2NHAG8ISkhansIuASYI6ks4EXyI5CIDvJPQnoAl4FzmomNjMz2/qa7Va6LDe+CVgGfKrRAhHxEPXPIwAcV6d+kN1sZ2ZmFWv2aqU/LzsQMzNrH812K32l0fwe5xTMzGwb15+rlY4kO2kM8AngQTa/L8HMzAaI/vzYz/h0pzOSZgA/jIjPlxWYmZlVp9nHZ4wGXs9Nvw6M2erRmJlZW2j2yOFmYL6kO8juWj4FuKm0qMzMrFLNXq00U9I9wJ+morMi4rHywjIzsyo1260EsDOwLiK+C3RLOqCkmMzMrGLN/kzoxcAFwIWpaHvgn8oKyszMqtXskcMpwCeBfweIiBX0/fgMMzPbRjWbHF5Pj7cIAEm7lBeSmZlVrdnkMEfSdWS/zvYF4Ods4Q//mJlZ+2v2aqXvpN+OXge8F/jbiJhXamRmZlaZPpODpCHATyPieMAJwcxsEOizWyki3gBelbR7C+IxM7M20Owd0q+R/WjPPNIVSwAR8V9KicrMzCrVbHL4SRrMzGwQaJgcJI2OiBciYnarAjIzs+r1dc7hn2sjkn7UnxVLulHSakmLc2UzJP1W0sI0TMrNu1BSl6Slkj7Wn22ZmdnW1VdyyP8G9IH9XPf3gBPrlF8REePScDeApEOBKcBhaZl/SFdJmZlZBfpKDtHLeJ8i4kHgpSarTwZujYiNEfE80AVM6M/2zMxs6+krOXxA0jpJ64HD0/g6SeslrdvCbZ4naVHqdtozlY1g858c7U5lBZKmSVogacGaNWu2MAQzM2ukYXKIiCER8a6I2C0ihqbx2vS7tmB71wAHAeOAlcBlqVx16tY9UomIWRHRGRGdHR0dWxCCmZn1pT+/5/CORcSqiHgjIt4kezZTreuoGxiVqzoSWNHK2MzM7G0tTQ6ShucmTwFqVzLNBaZIGpZ+RGgsML+VsZmZ2duavQmu3yTdAhwD7COpG7gYOEbSOLIuo2XAFwEiYomkOcCTwCbg3PTYDjMzq0BpySEiTq9TfEOD+jOBmWXFY2ZmzWtpt5KZmW0bnBzMzKzAycHMzAqcHMzMrMDJwczMCpwczMyswMnBzMwKnBzMzKzAycHMzAqcHMzMrMDJwczMCpwczMyswMnBzMwKnBzMzKzAycHMzAqcHMzMrMDJwczMCpwczMysoLTkIOlGSaslLc6V7SVpnqRn0uueqVySrpLUJWmRpPFlxWVmZn0r88jhe8CJPcqmA/dGxFjg3jQNcBIwNg3TgGtKjMvMzPpQWnKIiAeBl3oUTwZmp/HZwMm58psi80tgD0nDy4rNzMwaa/U5h/0iYiVAet03lY8AlufqdaeyAknTJC2QtGDNmjWlBmtmNli1ywlp1SmLehUjYlZEdEZEZ0dHR8lhmZkNTq1ODqtq3UXpdXUq7wZG5eqNBFa0ODYzM0tanRzmAlPT+FTgzlz5memqpYnAK7XuJzMza72hZa1Y0i3AMcA+krqBi4FLgDmSzgZeAE5L1e8GJgFdwKvAWWXFZWZmfSstOUTE6b3MOq5O3QDOLSsWMzPrn3Y5IW1mZm3EycHMzAqcHMzMrMDJwczMCpwczMyswMnBzMwKnBzMzKzAycHMzAqcHMzMrMDJwczMCpwczMyswMnBzMwKnBzMzKzAycHMzAqcHMzMrMDJwczMCpwczMyswMnBzMwKSvuZ0EYkLQPWA28AmyKiU9JewG3AGGAZ8KmIeLmK+MzMBrsqjxz+PCLGRURnmp4O3BsRY4F707SZmVWgnbqVJgOz0/hs4OQKYzEzG9SqSg4B/EzSo5KmpbL9ImIlQHrdt6LYzMwGvUrOOQBHR8QKSfsC8yQ93eyCKZlMAxg9enRZ8ZmZDWqVHDlExIr0uhq4A5gArJI0HCC9ru5l2VkR0RkRnR0dHa0K2cxsUGl5cpC0i6TdauPACcBiYC4wNVWbCtzZ6tjMzCxTRbfSfsAdkmrb/0FE/KukR4A5ks4GXgBOqyA2MzOjguQQEc8BH6hT/nvguFbHY2ZmRe10KauZmbUJJwczMytwcjAzswInBzMzK3ByMDOzAicHMzMrcHIwM7MCJwczMytwcjAzswInBzMzK3ByMDOzAicHMzMrcHIwM7MCJwczMytwcjAzswInBzMzK3ByMDOzgip+JnTQGzP9J5Vsd9klH69ku2a27fGRg5mZFbRdcpB0oqSlkrokTa86HjOzwaitupUkDQH+F/BRoBt4RNLciHiy2sgGhqq6s8BdWmbbmrZKDsAEoCsingOQdCswGXBy2MZVmZiq4oTYOv58bX3tlhxGAMtz093AUfkKkqYB09LkBklLt3Bb+wAvbuGy2yq3uYV0aRVb9T4eJPbRpe+ozfv3VaHdkoPqlMVmExGzgFnveEPSgojofKfr2Za4zQPfYGsvuM1labcT0t3AqNz0SGBFRbGYmQ1a7ZYcHgHGSjpA0g7AFGBuxTGZmQ06bdWtFBGbJJ0H/BQYAtwYEUtK2tw77praBrnNA99gay+4zaVQRPRdy8zMBpV261YyM7M24ORgZmYFgzI5bOuP6JC0TNITkhZKWpDK9pI0T9Iz6XXPVC5JV6W2LpI0Preeqan+M5Km5so/mNbflZatd4lx2W28UdJqSYtzZaW3sbdtVNjmGZJ+m/b1QkmTcvMuTPEvlfSxXHndz3e60OPh1Lbb0kUfSBqWprvS/DEtau8oSfdLekrSEklfTuUDcj83aG977uOIGFQD2YnuZ4EDgR2Ax4FDq46rn21YBuzTo+zvgelpfDpwaRqfBNxDdg/JRODhVL4X8Fx63TON75nmzQc+lJa5BzipgjZ+BBgPLG5lG3vbRoVtngF8rU7dQ9NndxhwQPpMD2n0+QbmAFPS+LXA36Txc4Br0/gU4LYWtXc4MD6N7wb8OrVrQO7nBu1ty33c0j/4dhjSB+WnuekLgQurjqufbVhGMTksBYbnPoRL0/h1wOk96wGnA9flyq9LZcOBp3Plm9VrcTvHsPkXZelt7G0bFba5ty+OzT63ZFf4fai3z3f6cnwRGJrK36pXWzaND031VMH+vpPsuWoDfj/3aG9b7uPB2K1U7xEdIyqKZUsF8DNJjyp7nAjAfhGxEiC97pvKe2tvo/LuOuXtoBVt7G0bVTovdaPcmOv+6G+b9wbWRsSmHuWbrSvNfyXVb5nUzXEE8DCDYD/3aC+04T4ejMmhz0d0bAOOjojxwEnAuZI+0qBub+3tb3k7G8htvAY4CBgHrAQuS+Vbs82Vvh+SdgV+BJwfEesaVa1Tts3t5zrtbct9PBiTwzb/iI6IWJFeVwN3kD3NdpWk4QDpdXWq3lt7G5WPrFPeDlrRxt62UYmIWBURb0TEm8D1ZPsa+t/mF4E9JA3tUb7ZutL83YGXtn5riiRtT/ZF+f2I+HEqHrD7uV5723UfD8bksE0/okPSLpJ2q40DJwCLydpQu0pjKll/Jqn8zHSlx0TglXQY/VPgBEl7psPYE8j6J1cC6yVNTFd2nJlbV9Va0cbetlGJ2hdYcgrZvoYszinpKpQDgLFkJ1/rfr4j62y+Hzg1Ld/z/au1+VTgvlS/VOm9vwF4KiIuz80akPu5t/a27T5u9UmYdhjIrnr4NdkZ/29UHU8/Yz+Q7OqEx4EltfjJ+g/vBZ5Jr3ulcpH9gNKzwBNAZ25dnwO60nBWrrwzfUCfBa6mmpOTt5AdYv+R7L+es1vRxt62UWGbb05tWpT+wIfn6n8jxb+U3BVlvX2+02dnfnovfggMS+U7pumuNP/AFrX3w2RdG4uAhWmYNFD3c4P2tuU+9uMzzMysYDB2K5mZWR+cHMzMrMDJwczMCpwczMyswMnBzMwKnBzMzKzAycHMzAr+P/CjBz7VsxjeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = X_train.attendance\n",
    "x.plot(kind='hist', title='Histogram of Attendance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The danger here lies around the 200,000 to 250,000 events. These are sort of outliers that can pull your ML algorithm towards it. In other words, the skewness of the data may be problematic for the ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py:679: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12.43320821811392"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_log = np.log(x) \n",
    "np_log.max()\n",
    "\n",
    "\n",
    "# np_log.plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.43320821811392"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_log.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116    True\n",
       "15     True\n",
       "276    True\n",
       "460    True\n",
       "486    True\n",
       "       ... \n",
       "299    True\n",
       "221    True\n",
       "478    True\n",
       "260    True\n",
       "148    True\n",
       "Name: attendance, Length: 396, dtype: bool"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isfinite(np_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function transformer\n",
    "\n",
    "When you look for a certain transformer and can't find it, Scikit-Learn provides a generic transformer tool. All you need to do is give it a function and it will be turned into a transformer.\n",
    "\n",
    "All you need to do is create a function transform object, pass in a function (in this case log1p which takes log and prevents infinite zeros from happening). Next, you simply call that function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-fbcb62b587d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFunctionTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "logger = FunctionTransformer(np.log1p)\n",
    "X_log = logger.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Alternatively***, you could write your own custom transformer. TransforMixin will do stuff automatically. The fit method doesn't need to do anything because there aren't any parameters that it needs to know from the training data. After all, you just want to transform stuff but nonetheless a fit function needs to be included because otherwise it's not accepted by TransformerMixin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class Log1pTransformer(TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        Xlog = np.log1p(X)\n",
    "        return Xlog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with the parks in our datasets\n",
    "\n",
    "The idea is one hot encoding (dummy encoding). The DictVectorizer that comes with ScikitLearn helps with this but it's not perfect yet.\n",
    "\n",
    "The ***DictVectorizer*** transforms lists of feature-value mappings to vectors. I.e. it turns feature names into feature values in NumPy arrays for use with estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "class DummyTransformer(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # create a field to hold that internal transformer \n",
    "        self.dv = None \n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        # X is a string input. We turn each row into a record. \n",
    "        # This is a mapping from the column name to the column value (0, 1)\n",
    "        # This is the format the dictvectorizer wants\n",
    "        Xdict = X.to_dict('records')\n",
    "        # apply the DictVectorizer method\n",
    "        self.dv = DictVectorizer(sparse=False)\n",
    "        # Fit the DictVectorizer method\n",
    "        self.dv.fit(Xdict)\n",
    "        # Return itself, which is equal to self.dv\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Turn the dataset into records\n",
    "        Xdict = X.to_dict('records')\n",
    "        # call the transform on the internal transformer\n",
    "        Xt = self.dv.transform(Xdict)\n",
    "        # Grab the feature names that it produces\n",
    "        cols = self.dv.get_feature_names()\n",
    "        # pull the index and throw it all back on and turn it into a dataframe\n",
    "        Xdum = pd.DataFrame(Xt, index=X.index, columns=cols)\n",
    "        return Xdum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas versus Scikit-Learn\n",
    "\n",
    "Pandas DataFrames...\n",
    "- support many datatypes\n",
    "- allow missing data\n",
    "- labeled rows and columns\n",
    "\n",
    "Scikit-Learn Models...\n",
    "- Expect all numeric features\n",
    "- Can't handle nulls (usually)\n",
    "- Cast to NumPy arrays\n",
    "\n",
    "We want to stay in Pandas land. We can do so as long as possible by having custom transformers that return DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFFeatureUnion(TransformerMixin):\n",
    "    # FeatureUnion but for pandas DataFrames\n",
    "\n",
    "    def __init__(self, transformer_list):\n",
    "        self.transformer_list = transformer_list\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for (name, t) in self.transformer_list:\n",
    "            t.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xts = [t.transform(X) for _, t in self.transformer_list]\n",
    "        Xunion = reduce(lambda X1, X2: pd.merge(X1, X2, left_index=True, right_index=True), Xts)\n",
    "        return Xunion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroFillTransformer(TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # stateless transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xz = X.fillna(value=0)\n",
    "        return Xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnExtractor(TransformerMixin):\n",
    "    # give it a list of columns we want\n",
    "    def __init__ (self, cols):\n",
    "        \n",
    "        self.cols = cols\n",
    "    \n",
    "    # doesn't do anything\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    # takes a certain column X and slices to those columns\n",
    "    def transform(self, X):\n",
    "        Xcols = X[self.cols]\n",
    "        return Xcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFStandardScaler(TransformerMixin):\n",
    "    # StandardScaler but for pandas DataFrames\n",
    "\n",
    "    def __init__(self):\n",
    "        self.ss = None\n",
    "        self.mean_ = None\n",
    "        self.scale_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.ss = StandardScaler()\n",
    "        self.ss.fit(X)\n",
    "        self.mean_ = pd.Series(self.ss.mean_, index=X.columns)\n",
    "        self.scale_ = pd.Series(self.ss.scale_, index=X.columns)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xss = self.ss.transform(X)\n",
    "        Xscaled = pd.DataFrame(Xss, index=X.index, columns=X.columns)\n",
    "        return Xscaled\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together - Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the categorical and numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_FEATS = [\n",
    "    'permit_type', 'event_category', 'event_sub_category', 'event_location_park', 'event_location_neighborhood'\n",
    "]\n",
    "NUM_FEATS = ['attendance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pipeline and include our custom FeatureUnion to simultaneously handle categoricals and numericals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', DFFeatureUnion([\n",
    "        ('categoricals', Pipeline([\n",
    "            ('extract', ColumnExtractor(CAT_FEATS)),\n",
    "            ('dummy', DummyTransformer())\n",
    "        ])),\n",
    "        ('numerics', Pipeline([\n",
    "            ('extract', ColumnExtractor(NUM_FEATS)),\n",
    "            ('zero_fill', ZeroFillTransformer()),\n",
    "            ('log', Log1pTransformer())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('scale', DFStandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "X_train = pipeline.fit_transform(df_train)\n",
    "X_test = pipeline.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-a002323288ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m-> 1527\u001b[0;31m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1528\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 578\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-56bec34c61a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1643\u001b[0m             \u001b[0mwhere\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0mare\u001b[0m \u001b[0mordered\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \"\"\"\n\u001b[0;32m-> 1645\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m         ovr = (self.multi_class in [\"ovr\", \"warn\"] or\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "p_pred_test = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure performance on test data set (first model had AUC = 0.57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_test = roc_auc_score(y_test, p_pred_test) #0.71"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
